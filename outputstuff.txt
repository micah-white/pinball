[171, 727, 874, 1376, 1195, 156]
[-9.04891378977815, 0.012168652717631947, 0.5729098223917353, 5.909693598256059, 4.953020335563701, -9.074730106145973]
resetting env. episode #1 reward total was 1.603000. running mean: 1.603000
[123, 498, 597, 956, 740, 81]
[-8.999959995466494, 0.1425720694444555, 0.5888502807772901, 5.834966154576499, 4.889711273116742, -9.084365803727069]
resetting env. episode #2 reward total was 0.572200. running mean: 1.592692
[170, 524, 680, 1046, 856, 122]
[-9.05153860971202, -0.11213990941958871, 0.40155435578243387, 5.727269298995446, 4.994953077930676, -9.07116589851577]
resetting env. episode #3 reward total was 1.223100. running mean: 1.588996
[135, 533, 643, 984, 793, 92]
[-8.92607114893693, 0.03439171147232766, 0.514681962803075, 5.661358658296875, 4.865007369490821, -9.087743623271098]
resetting env. episode #4 reward total was 1.052600. running mean: 1.583632
[120, 442, 572, 815, 709, 97]
[-9.195078723954909, 0.18828226013182936, 0.4173402064412788, 5.902432181456847, 4.84908838960973, -9.330765966445018]
resetting env. episode #5 reward total was 1.052700. running mean: 1.578323
[402, 1355, 1731, 2723, 2155, 263]
[-8.984501863358906, -0.08190345273108902, 0.48721426018882436, 5.768969554479151, 4.935320165446944, -9.193875095459783]
resetting env. episode #6 reward total was 4.656700. running mean: 1.609107
[74, 281, 345, 503, 409, 61]
[-8.834411489229785, -0.270319695745439, 0.3485366244997132, 5.5544031332310055, 5.0922652397381665, -9.101043675368066]
resetting env. episode #7 reward total was 0.450700. running mean: 1.597523
[36, 135, 152, 243, 180, 26]
[-8.951544757064633, 0.018217021100582587, 0.47371354072311234, 5.7546887369383874, 4.780418589219909, -9.093227247711107]
resetting env. episode #8 reward total was 0.081000. running mean: 1.582357
[105, 379, 480, 831, 641, 79]
[-8.834389636714048, 0.12556000630479502, 0.7695229968028857, 5.938395970210733, 4.8129797931385525, -8.90586334877751]
resetting env. episode #9 reward total was 0.273400. running mean: 1.569268
[165, 631, 818, 1280, 1044, 126]
[-8.913775069486716, 0.05941352875136107, 0.6290200871995001, 5.7221404868069, 4.984799793715745, -8.952991381604646]
resetting env. episode #10 reward total was 2.022900. running mean: 1.573804
overflow encountered in exp